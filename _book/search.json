[
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "twri r-manual",
    "section": "Requirements",
    "text": "Requirements\n\nR version 4.2 or higher. This can be installed from https://cran.r-project.org/ or using the Ivanti Installation Manager if you are on an AgriLife computer.\nRStudio Desktop is the integrated development environment used to write and execute R code. Available for free from RStudio or Posit. Admin privileges are required to install, so install from Ivanti on AgriLife computers.\nThe manual assumes some basic understanding of using R and RStudio, reach out to colleagues if you are having difficulty.\nMost of the functions and code make heavy use of the tidyverse ecosystem of packages and functions. In particular tibble, dplyr, ggplot2. You are encouraged to become familiar with these particular packages. If you are just starting out with R, the R for Data Science book (free!) is a recommended reading.\nProject oriented workflows are an absolute requirement. Create projects in RStudio that align with each project you work on. Store your source and raw data within the project. Export your processed data and figures within the project. The complexity of the project will vary according to the project needs and the analysts comfort in various R packages."
  },
  {
    "objectID": "01-intro.html#project-oriented-workflow",
    "href": "01-intro.html#project-oriented-workflow",
    "title": "\n1  Fundamentals\n",
    "section": "\n1.1 Project-oriented workflow",
    "text": "1.1 Project-oriented workflow\n\n\n\n\n\n\nNote\n\n\n\nThis subsection is largely based on Jenny Bryan’s What They Forgot (WTF) to Teach You About R.\n\n\n1 - Organize your work into a project. This means within the file system store all your data, code, figures, notes, and related material within the same folder and subfolders.\n2 - RStudio Projects enforces this approach. When you create a new project in RStudio, it creates a folder with some metadata and user options for that specific project (stored in the .Rproj file inside the folder it created for the project).\n3 - RStudio Projects establish a working directory and use relative file paths by default. Usually this is what you want so when you share a project or move it from one computer to the next, it. just. works. This is also why it is critical to store your data and scripts within the project.\nA typical project might have a file and folder structure like this:\n\n\n\n Project Folder\n|\n|-- Data\n|   |\n|   |-- Raw Data\n|   |-- More Raw Data\n|\n|-- Scripts\n|   |\n|   |-- Analysis.R file\n|   |-- Figures.R file\n|\n|-- Figures\n|   |\n|   |-- Plot\n|   |-- Another figure\n|\n|-- Exported Data\n|   |\n|   |-- Results\n|\n|--- Reports\n|   |\n|   |-- Report\n|\n|- Readme file (usually .Rmd, .md, or .txt file)\n\n\n\n\n\n1.1.1 Your RStudio Project\nStart a new project! Open RStudio, in the upper left click “File” -> “New Project.” We generally want to start a project in a New Directory, so click that. One the next window click New Project. Now you can choose the subdirectory name of your project (folder name) followed by where you want that subdirectory to be stored. Click “Create Project” and RStudio create the subdirectory and puts a .Rproj file with specific project info in there for you.\n\n\nExample RStudio workspace\n\n\nThe RStudio workspace includes 3 major components. In the upper left, the script area shows the content of open R scripts (or any text based file that you open will show up here). You can edit, save, and run lines of code from this window.\nAt the bottom left, is the R console. This is where R operates. The code you wrote in the script gets loaded into the console and R does whatever is in the script. Output, messages, and warnings from your R code will probably show up here.\nAt the bottom right, are a couple of tabs. This is where graphical outputs are displayed. There are also tabs for files, packages, and help. The file tab lets you navigate, create, delete, and open files and folders. It defaults to your projects working directory. The packages tab is for exploring the packages you have installed, more on that below. Technically you can load and unload packages from here by clicking boxes next to each package. Don’t do that. The help tab is just that, it lets you search functions in each package and displays the documentation for packages and functions. Learn to use this tab, it will help you just like it says!\n\n1.1.2 Running Code\nYou should generally write your code in the script window and execute it from there. This will save you from retyping code again and again.\nIf you have your cursor on an expression in your R script, use the keyboard shortcut: Ctrl+Enter to execute that expression. The cursor will automatically move to the next statement and the code will run in the console. If you want to execute the entire script at once, use the keyboard shortcut: Ctrl+Shift+S.\n\n1.1.3 Basic coding\nBoxes with the grey background and blue vertical bar indicate chunks of R code. If there is an output when that code chunk is run by R, the output (text output, tables or figures) will follow directly below the chunk. For example, here is a code chunk:\n\n10*100\n\nAnd this is the output:\n\n\n[1] 1000\n\n\n\n\n\n\n\n\nNote\n\n\n\nMuch of this subsection is from R for Data Science which you are encouraged to explore.\n\n\nThis: <-, is called an assignment operator in R. We use it to create objects by assigning a value to a variable name. We name objects so we can easily refer to whatever you assigned later on in your script:\n\nx <- 10\ny <- 100\n\nx * y\n\n[1] 1000\n\n\nYou don’t have to assign numbers:\n\nx <- \"Hello\"\n\nprint(x)\n\n[1] \"Hello\"\n\n\nAssignment operators go either direction, you might find it useful to use the left to right assinment operator in some situations:\n\n\"Hello\" -> x\n\nprint(x)\n\n[1] \"Hello\"\n\n\nHowever, for the most part, standard practice is to assign right to left so you can easily find the variable name receiving the value. Whatever you choose, use the same direction throughout your project.\nAs your scripts get more complicated, it is important to use descriptive object names. Object names can only contain letters, numbers, _, and ., so we recommend using “snake_case” to create object names:\nstreamflow\nstreamflow_site_a\nObject names are case sensitive, streamflow_site_a is not the same as streamflow_site_A.\nThe # symbol is ignored by R and used to include human readable comments in your script. Use comments liberally in your code.\n\n## I can write what I want\n## and R does not evaluate\n## this\na <- 1\na"
  },
  {
    "objectID": "01-intro.html#functions",
    "href": "01-intro.html#functions",
    "title": "\n1  Fundamentals\n",
    "section": "\n1.2 Functions",
    "text": "1.2 Functions\nFunctions are essentially tools that take input arguments and output some kind of value. Functions are the basis for most everything you do in R. For example, seq() is a function to generate a regular sequence of numbers. You can get to the help documentation by entering ?seq() in the console. It takes the arguments from, to, by, length.out, along.with. Use = for argument values:\n\nseq(from = 0, to = 10, by = 2)\n\n[1]  0  2  4  6  8 10\n\n\nWriting your own functions is one of the reasons for using R. Here is a simplistic function that generates a message in the console screen depending on the condition of the first argument.\n\nprint_hello <- function(x) {\n  if (x < 1) message(\"Hello!\")\n  else message(\"Bye\")\n}\n\nprint_hello(x = -1)\n\nHello!\n\nprint_hello(x = 1)\n\nBye\n\n\nWhy write a function in the first place? Sometimes you might need to repeatedly run the same set of functions on different data or subsets of data. You will find yourself copy and pasting code and changing some values within. If the output is dependent on some values you forgot to change when you cut and paste, instant problems! Functions let you skip that copy and paste action, and just update the arguments. Here is an example of some code to calculate the confidence interval around the mean for a vector of numbers:\n\nmin <- 0\nmax <- 10\nn <- 1000\nci <- 0.95\nx <- runif(n = n, min = min, max = max)\nse <- sd(x)/sqrt(length(x))\nalpha <- 1 - ci\nmean(x) + se * qnorm(c(alpha/2, 1-alpha/2))\n\n[1] 4.926802 5.291238\n\n\nIf we need to recalculate the confidence interval for different values or combinations of values of x, n, and ci we would have to cut and paste the chunk each time with the potential for data entry errors if the wrong values are entered. Instead, create a function and change the arguments as needed.\n\nci <- function(min, max, n, ci) {\n  x <- runif(n = n, min = min, max = max)\n  se <- sd(x)/sqrt(length(x))\n  alpha <- 1 - ci\n  mean(x) + se * qnorm(c(alpha/2, 1-alpha/2))\n}\n\nci(min = 0, max = 10, n = 1000, ci = 0.95)\n\n[1] 4.954985 5.317012\n\nci(min = 10, max = 100, n = 1000, ci = 0.90)\n\n[1] 52.74082 55.46551\n\nci(min = 10, max = 1000, n = 1000, ci = 0.80)\n\n[1] 492.4893 516.3169"
  },
  {
    "objectID": "01-intro.html#packages",
    "href": "01-intro.html#packages",
    "title": "\n1  Fundamentals\n",
    "section": "\n1.3 Packages",
    "text": "1.3 Packages\nPackages might be considered the toolboxes of R. They are generally a collection of functions and classes the expand the capabilities of the base R functions. Many packages have dependencies from other packages. This mean when you install one package, you may end up installing multiple other packages automatically that are required for the package that you chose to work. Normally this works without hiccup. However, before installing packages, I suggest restarting your R session and make sure no packages are currently loaded to prevent issues.\nMost packages can and should be installed from the CRAN repository. These are a network of repositories that host the official, up-to-date and approved packages for R. This packages are pre-built, meaning you are unlikely to run into issues on installation. To install packages from CRAN, you typically do something like the following:\n\n## install one package\ninstall.packages(\"ggplot2\")\n\n## install multiple packages\ninstall.packages(\"dplyr\", \"tidyr\")\n\nSometimes you need a package or package version that is not currently available on CRAN. There are various justifiable reasons the packages might not be available on CRAN; however, one of the benefits of using CRAN packages is that they are all reviewed by a person before acceptance. This provides a safety mechanism for not only the quality of the package but potential security issues.\n\n\n\n\n\n\nNote\n\n\n\nIf you are installing a package from GitHub or other source, please review it for safety and quality before installation.\n\n\nThere are two primary way to install non-CRAN packages. The preferred method is to install pre-built packages from an alternative repository like r-universe. The readme file associated with the package will generally inform you if the package is available on a different repository and how to install it from that repository.\nAn example of this is shown below for the adc package:\n\ninstall.packages('adc', repos = c(txwri = 'https://txwri.r-universe.dev'))\n\nAn alternative option is to download and build the packages from the source, such as GitHub. For those on Windows, you will need to install the RTools toolchain. Then, we can use the remotes package to download, build and install a package from GitHub:\n\ninstall.packages(\"remotes\")\nremotes::install_github(\"mps9506/rATTAINS\")\n\nAfter you install a package, you need to load the package in order to use the functions. Confusingly, you use the library() function to accomplish this. Standard practice is to load libraries at the top of your script:\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)"
  },
  {
    "objectID": "01-intro.html#other-coding-conventions",
    "href": "01-intro.html#other-coding-conventions",
    "title": "\n1  Fundamentals\n",
    "section": "\n1.4 Other Coding Conventions",
    "text": "1.4 Other Coding Conventions\nPlaceholder.\nTopics: strings, Date formats, pipe function"
  },
  {
    "objectID": "02-data_exploration.html#import-data",
    "href": "02-data_exploration.html#import-data",
    "title": "\n2  Data Exploration\n",
    "section": "\n2.1 Import Data",
    "text": "2.1 Import Data\nself-note - create multisite dataset (flow?)\nOne of the first steps in any data analysis project is importing or reading data into R. For now, we will focus on reading in data from comma separated value (CSV), tab seperated value (TSV), and similar delimited text files. For most projects, it is useful to work off a singular data snapshot. So once you download your data and have it in your project, do not manipulate the data file1.\nObtain your data and copy it into the data folder in your R project. If you want to work along, download the following\nUse the read_csv() function from the readr package to import the data and assign it to a variable. The console will print some information telling you what type of variable it made each column of the csv and if there are any problems.\n\ndf <- read_csv(file = \"data/easterwood.csv\")\n\nRows: 4045 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): name\ndbl  (3): station, dailymaximumdrybulbtemperature, dailyprecipitation\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nread_csv() guesses the column types and sometimes it can guess wrong, so the safest option is to tell it what to expect using the col_types argument. This argument takes a string where each character represents one column. Here we will tell it to expect a character, Date, character, number, number which is represented as cDcnn.\n\ndf <- read_csv(file = \"data/easterwood.csv\",\n               col_types = \"cDcnn\")\ndf\n\n# A tibble: 4,045 × 5\n   station     date       name                 dailymaximumdry… dailyprecipitat…\n   <chr>       <date>     <chr>                           <dbl>            <dbl>\n 1 74746003904 2010-07-31 COLLEGE STATION EAS…               99                0\n 2 74746003904 2010-08-01 COLLEGE STATION EAS…              102                0\n 3 74746003904 2010-08-02 COLLEGE STATION EAS…              101                0\n 4 74746003904 2010-08-03 COLLEGE STATION EAS…              100                0\n 5 74746003904 2010-08-04 COLLEGE STATION EAS…               99                0\n 6 74746003904 2010-08-05 COLLEGE STATION EAS…               99                0\n 7 74746003904 2010-08-06 COLLEGE STATION EAS…               99                0\n 8 74746003904 2010-08-07 COLLEGE STATION EAS…               99                0\n 9 74746003904 2010-08-08 COLLEGE STATION EAS…               99                0\n10 74746003904 2010-08-09 COLLEGE STATION EAS…              100                0\n# … with 4,035 more rows\n\n\nTSV and other delimited files are read in the same way but with read_delim() or read_tsv(). If your data is in .xlsx format, the readxl pacakge is required. In readxl there is a read_xlsx() function that works similar to the read_csv() function except you can specify the sheet and range of cells to read from. The col_types argument also needs to be spelled out as a character vector such as col_types = c(\"text\", \"date\", \"text\", \"numeric\", \"numeric\").\nIf you have multiple files with the same column names you can read them into the same data frame. Here we read in multiple files and are more explicit about defining the column types:\n\nfiles <- c(\"data/marabwq2020.csv\", \"data/marabwq2021.csv\", \"data/marcewq2020.csv\", \"data/marcewq2021.csv\")\ndf <- read_csv(file = files, \n               col_types = cols_only(\n                 StationCode = col_factor(),\n                 DateTimeStamp = col_datetime(format = \"%m/%e/%Y %H:%M\"),\n                 Temp = col_number(),\n                 F_Temp = col_character(),\n                 SpCond = col_number(),\n                 F_SpCond = col_character(),\n                 Sal = col_number(),\n                 F_Sal = col_character(),\n                 DO_mgl = col_number(),\n                 F_DO_mgl = col_character()\n               ))\ndf\n\n# A tibble: 140,352 × 10\n   StationCode DateTimeStamp        Temp F_Temp SpCond F_SpCond   Sal F_Sal\n   <fct>       <dttm>              <dbl> <chr>   <dbl> <chr>    <dbl> <chr>\n 1 marabwq     2020-01-01 00:00:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 2 marabwq     2020-01-01 00:15:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 3 marabwq     2020-01-01 00:30:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 4 marabwq     2020-01-01 00:45:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 5 marabwq     2020-01-01 01:00:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 6 marabwq     2020-01-01 01:15:00  15.5 <0>      38.2 <0>       24.4 <0>  \n 7 marabwq     2020-01-01 01:30:00  15.5 <0>      38.3 <0>       24.4 <0>  \n 8 marabwq     2020-01-01 01:45:00  15.5 <0>      38.3 <0>       24.4 <0>  \n 9 marabwq     2020-01-01 02:00:00  15.5 <0>      38.3 <0>       24.4 <0>  \n10 marabwq     2020-01-01 02:15:00  15.5 <0>      38.3 <0>       24.4 <0>  \n# … with 140,342 more rows, and 2 more variables: DO_mgl <dbl>, F_DO_mgl <chr>\n\n\nIn this data we have a row for each date/time observation with associated columns for Station, Temperature, Specific Conductance, Salinity, and Dissolved Oxygen. The columns with the F_ prefix are qa/qc flags, <0> is accepted data."
  },
  {
    "objectID": "02-data_exploration.html#plot-and-clean-data",
    "href": "02-data_exploration.html#plot-and-clean-data",
    "title": "\n2  Data Exploration\n",
    "section": "\n2.2 Plot and Clean Data",
    "text": "2.2 Plot and Clean Data\nggplot2 is the graphics package for producing layered plots. The underlying philosophy of ggplot2 is to iteratively build your plots layer by layer which allows for some sophisticated plots. I won’t go into full details of using ggplot2 but lots of information is available in the ggplot2 book.\nThree key things you need to learn: data, aesthetics, geoms.\n\ndata: a data frame or tibble with the data you want to plot.\naesthetics mappings (or aes): specify how variables will be visually depicted (x, y, color, shape, size, etc.).\ngeoms: are the layers that define how each layer is rendered (points, lines, bars, etc.).\n\nUsing the data we imported from above we can quickly create a basic scatter plot. Note the use of the + symbol to iteratively add layers to our plot. First we specify the data, then the geometry, and the aesthetic for that geom:\n\np1 <- ggplot(data = df, aes(x = DateTimeStamp, y = Temp)) +\n  geom_point()\np1\n\nWarning: Removed 4975 rows containing missing values (geom_point).\n\n\n\n\n\nThe above figure demonstrates the importance of plotting your data, the -100 value is clearly an issue. One thing we can do is filter the data to try and track down the issue. The dplyr package provides a number of functions to explore your data. Here, the data is filtered on the Temp column to include data less than -99:\n\ndf |> \n  filter(Temp < -99)\n\n# A tibble: 1 × 10\n  StationCode DateTimeStamp        Temp F_Temp       SpCond F_SpCond   Sal F_Sal\n  <fct>       <dttm>              <dbl> <chr>         <dbl> <chr>    <dbl> <chr>\n1 marcewq     2021-08-23 20:45:00  -100 <-3> [GIM] … -1211. <-3> [G…   -99 <-3>…\n# … with 2 more variables: DO_mgl <dbl>, F_DO_mgl <chr>\n\n\nThe F_Temp qa flag is < -3 > indicating QA rejected the data point. So, let’s update the data to remove data that doesn’t have the < 0 > data flag:\n\ndf <- df |> \n  filter(F_Temp == \"<0>\")\ndf\n\n# A tibble: 111,090 × 10\n   StationCode DateTimeStamp        Temp F_Temp SpCond F_SpCond   Sal F_Sal\n   <fct>       <dttm>              <dbl> <chr>   <dbl> <chr>    <dbl> <chr>\n 1 marabwq     2020-01-01 00:00:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 2 marabwq     2020-01-01 00:15:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 3 marabwq     2020-01-01 00:30:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 4 marabwq     2020-01-01 00:45:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 5 marabwq     2020-01-01 01:00:00  15.5 <0>      38.2 <0>       24.3 <0>  \n 6 marabwq     2020-01-01 01:15:00  15.5 <0>      38.2 <0>       24.4 <0>  \n 7 marabwq     2020-01-01 01:30:00  15.5 <0>      38.3 <0>       24.4 <0>  \n 8 marabwq     2020-01-01 01:45:00  15.5 <0>      38.3 <0>       24.4 <0>  \n 9 marabwq     2020-01-01 02:00:00  15.5 <0>      38.3 <0>       24.4 <0>  \n10 marabwq     2020-01-01 02:15:00  15.5 <0>      38.3 <0>       24.4 <0>  \n# … with 111,080 more rows, and 2 more variables: DO_mgl <dbl>, F_DO_mgl <chr>\n\n\nThis removes about 29,263 observations. Try plotting again:\n\np1 <- ggplot(data = df, aes(x = DateTimeStamp, y = Temp)) +\n  geom_point()\np1\n\n\n\n\nWe can use different geoms to explore the data:\n\np2 <- ggplot(data = df, aes(x = Temp)) +\n  geom_histogram(binwidth = 1)\np2\n\n\n\n\nTo explore relationships between two variables, use geom_point and geom_smooth with each variable mapped to x and y. In this example, ggplot2 prints a message indicating 834 rows of data had missing or NA values that could not be plotted. geom_mooth will plot the smooth line (using a loess or gam smooth) between two variables. If you want the linear regression drawn use the argument method = \"lm\".\n\np3 <- ggplot(data = df, aes(x = Temp, y = DO_mgl)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(se = FALSE)\np3\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point).\n\n\n\n\n\nThis is a good example to introduce the other important aesthetics in ggplot2. There is a clear negative relationship between Temperature and Dissolved Oxygen. Our data includes two sites, is there a difference between the two sites? We can map color to the site variable which will color each observation and each smooth a different color. Although shape and color can be used inside the aes() mapping function, you can assign them a value in the geom directly. Here we asign values for the shape and alpha properties in the point geom.\n\np3 <- ggplot(data = df, aes(x = Temp, y = DO_mgl, color = StationCode)) +\n  geom_point(shape = 21, alpha = 0.05) +\n  geom_smooth(se = FALSE)\np3\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point).\n\n\n\n\n\nThere was no reason to expect a difference and there isn’t. However the plot is muddy because there are so many overlying data points. We can also facet the graph by a variable. The following code also shows how you can just add another layer to your existing ggplot object:\n\np3 <- p3 +\n  facet_wrap(~StationCode)\n\np3\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point).\n\n\n\n\n\nAs you can see, ggplot2 allows you to rapidly iterate plots to explore data. When exploring the data, the formatting might not matter much, but if you want to export plots, we also need to take care of labels and general plot visual preferences.\n\np3 <- p3 +\n  labs(x = \"Temperature [°F]\", y = \"Dissolved Oxygen [mg/L]\") +\n  scale_colour_brewer(name = \"Stations\",\n                      palette = \"Dark2\",\n                      labels = c(\"Aransas Bay\", \"Copano East\"))\np3\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point).\n\n\n\n\n\n\n2.2.1 Themes\nggplot2 has a number of built-in themes. For most of our use cases (reports and papers), the grey background and white lines are not great choices. We recommend using the theme_bw() function at the bare minimum:\n\np3 +\n  theme_bw()\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point).\n\n\n\n\n\nThe twriTemplates package is available with a custom theme and some color palettes that are consistent with the Institute’s branding:\n\ninstall.packages(\"twriTemplates\", \n                 repos = c(txwri = 'https://txwri.r-universe.dev',\n                           CRAN = 'https://cloud.r-project.org'))\n\n\nlibrary(twriTemplates)\np3 +\n  theme_TWRI_print() +\n  scale_color_discrete_twri(name = \"Stations\",\n                            labels = c(\"Aransas Bay\", \"Copano East\"))\n\nWarning: Removed 834 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 834 rows containing missing values (geom_point)."
  },
  {
    "objectID": "02-data_exploration.html#summarize-data",
    "href": "02-data_exploration.html#summarize-data",
    "title": "\n2  Data Exploration\n",
    "section": "\n2.3 Summarize Data",
    "text": "2.3 Summarize Data"
  },
  {
    "objectID": "02-data_exploration.html#export-data",
    "href": "02-data_exploration.html#export-data",
    "title": "\n2  Data Exploration\n",
    "section": "\n2.4 Export Data",
    "text": "2.4 Export Data"
  },
  {
    "objectID": "03-streamflow.html#data-sources",
    "href": "03-streamflow.html#data-sources",
    "title": "3  Streamflow Data",
    "section": "3.1 Data Sources",
    "text": "3.1 Data Sources"
  },
  {
    "objectID": "03-streamflow.html#summarise",
    "href": "03-streamflow.html#summarise",
    "title": "3  Streamflow Data",
    "section": "3.2 Summarise",
    "text": "3.2 Summarise"
  },
  {
    "objectID": "03-streamflow.html#flow-duration-curve",
    "href": "03-streamflow.html#flow-duration-curve",
    "title": "3  Streamflow Data",
    "section": "3.3 Flow Duration Curve",
    "text": "3.3 Flow Duration Curve"
  },
  {
    "objectID": "04-stage-discharge.html",
    "href": "04-stage-discharge.html",
    "title": "4  Stage-Discharge Rating Curves",
    "section": "",
    "text": "Placeholder"
  },
  {
    "objectID": "05-water-quality.html",
    "href": "05-water-quality.html",
    "title": "5  Water Quality Data",
    "section": "",
    "text": "Placeholder"
  },
  {
    "objectID": "06-load-duration.html",
    "href": "06-load-duration.html",
    "title": "6  Load Duration Curves",
    "section": "",
    "text": "Placeholder"
  },
  {
    "objectID": "08-watershed-delineation.html",
    "href": "08-watershed-delineation.html",
    "title": "8  Delineate Watersheds",
    "section": "",
    "text": "Placeholder"
  },
  {
    "objectID": "09-raster-summary.html",
    "href": "09-raster-summary.html",
    "title": "9  Extract Raster Summaries",
    "section": "",
    "text": "Placeholder"
  }
]